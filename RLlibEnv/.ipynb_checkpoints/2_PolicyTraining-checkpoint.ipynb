{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: When running this notebook on SageMaker Studio, you should make sure the 'SageMaker JumpStart Tensorflow 1.0' image/kernel is used. You can run run all cells at once or step through the notebook.\n",
    "# Policy Training\n",
    "\n",
    "This notebook outlines the steps involved in building and deploying a Battlesnake model using Ray RLlib and TensorFlow on Amazon SageMaker.\n",
    "\n",
    "Library versions currently in use:  TensorFlow 2.1, Ray RLlib 0.8.2\n",
    "\n",
    "The model is first trained using multi-agent PPO, and then deployed to a managed _TensorFlow Serving_ SageMaker endpoint that can be used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
    "import boto3\n",
    "import botocore\n",
    "import json\n",
    "from sagemaker.tuner import (IntegerParameter, CategoricalParameter, ContinuousParameter, \n",
    "                             HyperparameterTuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../stack_outputs.json\") as f:\n",
    "    info = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise sagemaker\n",
    "We need to define several parameters prior to running the training job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket path: s3://sagemaker-soln-bs-snake-bucket-farbod/\n"
     ]
    }
   ],
   "source": [
    "sm_session = sagemaker.session.Session()\n",
    "s3_bucket = info[\"S3Bucket\"]\n",
    "\n",
    "s3_output_path = 's3://{}/'.format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::681627153266:role/sagemaker-soln-bs-us-west-2-nb-role\n"
     ]
    }
   ],
   "source": [
    "job_name_prefix = info[\"SolutionPrefix\"]+'-job-rllib'\n",
    "\n",
    "role = info[\"SageMakerIamRoleArn\"]\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change local_mode to True if you want to do local training within this Notebook instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = 'local'\n",
    "else:\n",
    "    instance_type = info[\"SagemakerTrainingInstanceType\"]\n",
    "    \n",
    "# If training locally, do some Docker housekeeping..\n",
    "if local_mode:\n",
    "    !/bin/bash ./common/setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = sm_session.boto_region_name\n",
    "device = \"cpu\"\n",
    "image_name = '462105765813.dkr.ecr.{region}.amazonaws.com/sagemaker-rl-ray-container:ray-0.8.2-tf-{device}-py36'.format(region=region, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "image_name has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.4 ms, sys: 40 Âµs, total: 21.5 ms\n",
      "Wall time: 24.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define and execute our training job\n",
    "# Adjust hyperparameters and train_instance_count accordingly\n",
    "\n",
    "metric_definitions =  [\n",
    "#     {'Name': 'training_iteration', 'Regex': 'training_iteration: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "#     {'Name': 'episodes_total', 'Regex': 'episodes_total: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "#     {'Name': 'num_steps_trained', 'Regex': 'num_steps_trained: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'timesteps_total', 'Regex': 'timesteps_total: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}\n",
    "#     {'Name': 'training_iteration', 'Regex': 'training_iteration: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "\n",
    "#     {'Name': 'episode_reward_max', 'Regex': 'episode_reward_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "#     {'Name': 'episode_reward_mean', 'Regex': 'episode_reward_mean: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "#     {'Name': 'episode_reward_min', 'Regex': 'episode_reward_min: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    \n",
    "#     {'Name': 'episode_len_max', 'Regex': 'episode_len_mean: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "#     {'Name': 'episode_len_mean', 'Regex': 'episode_len_mean: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "#     {'Name': 'episode_len_min', 'Regex': 'episode_len_mean: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "\n",
    "#     {'Name': 'best_snake_episode_len_max', 'Regex': 'best_snake_episode_len_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "#     {'Name': 'worst_snake_episode_len_max', 'Regex': 'worst_snake_episode_len_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "\n",
    "#     {'Name': 'Snake_hit_wall_max', 'Regex': 'Snake_hit_wall_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "#     {'Name': 'Snake_was_eaten_max', 'Regex': 'Snake_was_eaten_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "#     {'Name': 'Killed_another_snake_max', 'Regex': 'Killed_another_snake_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "#     {'Name': 'Snake_hit_body_max', 'Regex': 'Snake_hit_body_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "#     {'Name': 'Starved_max', 'Regex': 'Starved_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "#     {'Name': 'Forbidden_move_max', 'Regex': 'Forbidden_move_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}\n",
    "] \n",
    "\n",
    "algorithm = \"PPO\"\n",
    "map_size = 11\n",
    "num_agents = 4\n",
    "additional_config = {\n",
    "    'lambda': 0.90,\n",
    "    'gamma': 0.999,\n",
    "    'kl_coeff': 0.2,\n",
    "    'clip_rewards': True,\n",
    "    'vf_clip_param': 175.0,\n",
    "    'train_batch_size': 9216,\n",
    "    'sample_batch_size': 96,\n",
    "    'sgd_minibatch_size': 256,\n",
    "    'num_sgd_iter': 3,\n",
    "    'lr': 5.0e-4,\n",
    "}\n",
    "\n",
    "estimator = RLEstimator(entry_point=\"train-mabs.py\",\n",
    "                        source_dir='training/training_src',\n",
    "                        dependencies=[\"training/common/sagemaker_rl\", \"inference/inference_src/\", \"../BattlesnakeGym/\"],\n",
    "                        toolkit=RLToolkit.COACH,\n",
    "                        toolkit_version=RLEstimator.COACH_LATEST_VERSION_MXNET,\n",
    "                        framework=RLFramework.MXNET,\n",
    "                        image_name=image_name,\n",
    "                        role=role,\n",
    "                        train_instance_type=instance_type,\n",
    "                        train_instance_count=1,\n",
    "                        output_path=s3_output_path,\n",
    "                        base_job_name=job_name_prefix,\n",
    "                        metric_definitions=metric_definitions,\n",
    "                        hyperparameters={\n",
    "                            # See train-mabs.py to add additional hyperparameters\n",
    "                            # Also see ray_launcher.py for the rl.training.* hyperparameters\n",
    "                            \n",
    "                            \"num_iters\": 15,\n",
    "                            # number of snakes in the gym\n",
    "                            \"num_agents\": num_agents,\n",
    "\n",
    "                            \"iterate_map_size\": False,\n",
    "                            \"map_size\": map_size,\n",
    "                            \"algorithm\": algorithm,\n",
    "                            \"additional_configs\": additional_config,\n",
    "                            \"use_heuristics_action_masks\": False\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "# estimator.fit()\n",
    "\n",
    "# job_name = estimator.latest_training_job.job_name\n",
    "# print(\"Training job: %s\" % job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateHyperParameterTuningJob operation: A metric is required for this hyperparameter tuning job objective. Provide a metric in the metric definitions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4bb7471d1d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                             base_tuning_job_name=job_name_prefix)\n\u001b[1;32m     28\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_hpo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, job_name, include_cls_metadata, estimator_kwargs, wait, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \"\"\"\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_with_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_cls_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_with_estimator_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_cls_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36m_fit_with_estimator\u001b[0;34m(self, inputs, job_name, include_cls_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_estimator_for_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_cls_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_cls_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_tuning_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TuningJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit_with_estimator_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_cls_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, tuner, inputs)\u001b[0m\n\u001b[1;32m   1507\u001b[0m             ]\n\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m         \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_tuning_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtuner_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_tuning_job\u001b[0;34m(self, job_name, tuning_config, training_config, training_config_list, warm_start_config, tags)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating hyperparameter tuning job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tune request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2052\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_hyper_parameter_tuning_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtune_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdescribe_tuning_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateHyperParameterTuningJob operation: A metric is required for this hyperparameter tuning job objective. Provide a metric in the metric definitions."
     ]
    }
   ],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'buffer_size': IntegerParameter(1000, 6000),\n",
    "    'update_every': IntegerParameter(10, 20),\n",
    "    'batch_size': IntegerParameter(16, 256),\n",
    "\n",
    "    'lr_start': ContinuousParameter(1e-5, 1e-3),\n",
    "    'lr_factor': ContinuousParameter(0.5, 1.0),\n",
    "    'lr_step': IntegerParameter(5000, 30000),\n",
    "    \n",
    "    'tau': ContinuousParameter(1e-4, 1e-3),\n",
    "    'gamma': ContinuousParameter(0.85, 0.99),\n",
    "    \n",
    "    'depth': IntegerParameter(10, 256),\n",
    "    'depthS': IntegerParameter(10, 256),\n",
    "}\n",
    "\n",
    "max_jobs = 3\n",
    "max_parallel_jobs = 3\n",
    "run_hpo = True\n",
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name='timesteps',\n",
    "                            objective_type='Maximize',\n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            max_jobs=max_jobs,\n",
    "                            max_parallel_jobs=max_parallel_jobs,\n",
    "                            base_tuning_job_name=job_name_prefix)\n",
    "if run_hpo:\n",
    "    tuner.fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-soln-bs-snake-bucket-farbod/sagemaker-soln-bs-job-rllib-2021-08-07-00-37-55-315/output/model.tar.gz'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where is the model stored in S3?\n",
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an endpoint to host the policy\n",
    "Firstly, we will delete the previous endpoint and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 6.2 MiB/6.2 MiB (19.7 MiB/s) with 1 file(s) remaining\r",
      "copy: s3://sagemaker-soln-bs-snake-bucket-farbod/sagemaker-soln-bs-job-rllib-2021-08-07-00-37-55-315/output/model.tar.gz to s3://sagemaker-soln-bs-snake-bucket-farbod/pretrainedmodels/model.tar.gz\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class sagemaker.tensorflow.serving.Model has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "sm_client = boto3.client(service_name='sagemaker')\n",
    "waiter = sm_client.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=info['SagemakerEndPointName'])\n",
    "try:\n",
    "    sm_client.delete_endpoint(EndpointName=info['SagemakerEndPointName'])\n",
    "    sm_client.delete_endpoint_config(EndpointConfigName=info['SagemakerEndPointName'])\n",
    "    sm_client.delete_model(ModelName=info['SagemakerEndPointName'])\n",
    "    ep_waiter = sm_client.get_waiter('endpoint_deleted')\n",
    "    ep_waiter.wait(EndpointName=info['SagemakerEndPointName'])\n",
    "except botocore.exceptions.ClientError:\n",
    "    pass\n",
    "    \n",
    "# Copy the endpoint to a central location\n",
    "model_data = \"s3://{}/pretrainedmodels/model.tar.gz\".format(s3_bucket)\n",
    "!aws s3 cp {estimator.model_data} {model_data}\n",
    "\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model = Model(model_data=model_data,\n",
    "              role=role,\n",
    "              entry_point=\"inference.py\",\n",
    "              source_dir='inference/inference_src',\n",
    "              framework_version='2.1.0',\n",
    "              name=info['SagemakerEndPointName'],\n",
    "              code_location='s3://{}//code'.format(s3_bucket)\n",
    "             )\n",
    "\n",
    "if local_mode:\n",
    "    inf_instance_type = 'local'\n",
    "else:\n",
    "    inf_instance_type = info[\"SagemakerInferenceInstanceType\"]\n",
    "\n",
    "# Deploy an inference endpoint\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=inf_instance_type,\n",
    "                         endpoint_name=info['SagemakerEndPointName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the endpoint\n",
    "\n",
    "This example is using single observation for a 5-agent environment \n",
    "The last axis is 12 because the current MultiAgentEnv is concatenating 2 frames\n",
    "5 agent maps + 1 food map = 6 maps total    6 maps * 2 frames = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "state = np.zeros(shape=(1, 21, 21, 6), dtype=np.float32).tolist()\n",
    "\n",
    "health_dict = {0: 50, 1: 50}\n",
    "json = {\"turn\": 4,\n",
    "        \"board\": {\n",
    "                \"height\": 11,\n",
    "                \"width\": 11,\n",
    "                \"food\": [],\n",
    "                \"snakes\": []\n",
    "                },\n",
    "            \"you\": {\n",
    "                \"id\": \"snake-id-string\",\n",
    "                \"name\": \"Sneky Snek\",\n",
    "                \"health\": 90,\n",
    "                \"body\": [{\"x\": 1, \"y\": 3}]\n",
    "                }\n",
    "            }\n",
    "\n",
    "before = time()\n",
    "action_mask = np.array([1, 1, 1, 1]).tolist()\n",
    "\n",
    "action = predictor.predict({\"state\": state, \"action_mask\": action_mask,\n",
    "                            \"prev_action\": -1, \n",
    "                           \"prev_reward\": -1, \"seq_lens\": -1,  \n",
    "                           \"all_health\": health_dict, \"json\": json})\n",
    "elapsed = time() - before\n",
    "\n",
    "action_to_take = action[\"outputs\"][\"heuristisc_action\"]\n",
    "print(\"Action to take {}\".format(action_to_take))\n",
    "print(\"Inference took %.2f ms\" % (elapsed*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "- To go back to the introduction click [here](./1_Introduction.ipynb)\n",
    "- To build some heuristics click [here](./3_HeuristicsDeveloper.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
